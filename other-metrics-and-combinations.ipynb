{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e296690-214b-4b8e-8dfa-9194cf953fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch is running on cuda\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as TVDatasets\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data as GraphData \n",
    "\n",
    "from torch_geometric.nn import GCNConv, GATConv, APPNP, SAGEConv\n",
    "from torch_geometric.nn.models.label_prop import LabelPropagation\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "# from sklearn.calibration import CalibrationDisplay\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "%matplotlib inline\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Torch is running on {device}\")\n",
    "\n",
    "\n",
    "import sys\n",
    "from gnn_cp.data.data_manager import GraphDataManager\n",
    "from gnn_cp.models.graph_models import GCN, GAT, APPNPNet, SAGE\n",
    "from gnn_cp.models.model_manager import GraphModelManager\n",
    "from gnn_cp.data.utils import make_dataset_instances\n",
    "import gnn_cp.cp.transformations as cp_t\n",
    "import gnn_cp.cp.graph_transformations as cp_gt\n",
    "from gnn_cp.cp.graph_cp import GraphCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aca01ee-f282-414e-baeb-6bab1d930ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file_dir = \"../baselines/config.yaml\"\n",
    "results_dir = \"../baselines/results\"\n",
    "figures_dir = \"./figures\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bee43a1-cf5d-41b4-8aef-cd544e05f6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specify the dataset index:\n",
      "0: cora_ml\n",
      "1: pubmed\n",
      "2: citeseer\n",
      "3: coauthor_cs\n",
      "4: coauthor_physics\n",
      "5: amazon_computers\n",
      "6: amazon_photo\n",
      " 2\n",
      "specify the model index:\n",
      "0: GCN\n",
      "1: GAT\n",
      "2: SAGE\n",
      "3: MLP\n",
      "4: APPNPNet\n",
      " 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset = citeseer\n",
      "Dataset Loaded Successfully!\n",
      "Following labeled splits:\n",
      "class 0: train=19, val=19\n",
      "class 1: train=19, val=19\n",
      "class 2: train=19, val=19\n",
      "class 3: train=19, val=19\n",
      "class 4: train=19, val=19\n",
      "class 5: train=19, val=19\n",
      "====================================\n",
      "Loading Models\n",
      "Loading Models GAT\n",
      "Accuracy: 0.8317841079460271 +- 0.009164523474374688\n",
      "acc=0.8317841079460271 +- 0.009164523474374688\n"
     ]
    }
   ],
   "source": [
    "# loading the baseline settings\n",
    "with open(config_file_dir, 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "general_dataset_config = config.get(\"baseline\", {}).get(\"general_dataset_config\", {})\n",
    "\n",
    "\n",
    "assert os.path.isdir(results_dir), \"The results path does not exist!\"\n",
    "\n",
    "models_cache_dir = os.path.join(results_dir, \"models\")\n",
    "assert os.path.isdir(models_cache_dir), \"Directory to trained models is not found! Maybe first tun the make_baselines.py file\"\n",
    "data_dir = os.path.join(results_dir, \"datasets\")\n",
    "assert os.path.isdir(data_dir), \"Directory to Data Files is not found!\"\n",
    "splits_dir = os.path.join(results_dir, \"splits\")\n",
    "assert os.path.isdir(splits_dir), \"Directory to Data Splits is not found!\"\n",
    "\n",
    "dataset_names = list(config.get(\"baseline\", {}).get(\"datasets\", {}).keys())\n",
    "models_config = config.get(\"baseline\", {}).get(\"models\", {})\n",
    "model_classes = list(models_config.keys())\n",
    "\n",
    "# Making a directory to store results for CPs\n",
    "cp_results_dir = os.path.join(results_dir, \"cp_results\")\n",
    "if not os.path.isdir(cp_results_dir):\n",
    "    os.mkdir(cp_results_dir)\n",
    "\n",
    "\n",
    "# region\n",
    "# Making dataset-split and model instances\n",
    "dataset_str_list = '\\n'.join([f'{i}: {dataset_name}' for i, dataset_name in enumerate(dataset_names)])\n",
    "dataset_name_idx = int(input(f\"specify the dataset index:\\n{dataset_str_list}\\n\"))\n",
    "dataset_key = dataset_names[int(dataset_name_idx)]\n",
    "\n",
    "model_str_list = '\\n'.join([f'{i}: {model_name}' for i, model_name in enumerate(model_classes)])\n",
    "model_class_idx = int(input(f\"specify the model index:\\n{model_str_list}\\n\"))\n",
    "model_class_name = model_classes[model_class_idx]\n",
    "\n",
    "dataset_manager = GraphDataManager(data_dir, splits_dir)\n",
    "dataset = dataset_manager.get_dataset_from_key(dataset_key).data\n",
    "\n",
    "print(f\"dataset = {dataset_key}\")\n",
    "instances = make_dataset_instances(data_dir, splits_dir, models_cache_dir, dataset_key, model_class_name, models_config)\n",
    "\n",
    "instances_accuracy = [instance[\"accuracy\"] for instance in instances]\n",
    "print(f\"acc={np.mean(instances_accuracy)} +- {np.std(instances_accuracy)}\")\n",
    "best_model_accuracy = np.max(instances_accuracy)\n",
    "\n",
    "instances_logits = [\n",
    "    instance[\"model\"].predict(dataset) for instance in instances\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857fbef9-5505-4f34-84f4-bd2b0fa0608c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathways = {\n",
    "    \"baseline\": GraphCP(transformation_sequence=[cp_t.APSTransformation(softmax=True)]),\n",
    "    \"regular\": GraphCP(transformation_sequence=[cp_t.APSTransformation(softmax=True)])\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Conformal Prediction Project",
   "language": "python",
   "name": "conformal-prediction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
